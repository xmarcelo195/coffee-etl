{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install great_expectations"
      ],
      "metadata": {
        "id": "WuBt-V24A-bw"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "opgMsM6Ju2XN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import sqlite3 as sql\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import great_expectations as ge"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criar ambiente sqlite\n"
      ],
      "metadata": {
        "id": "IrleVW0a632S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext sql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBjRTNSk5h09",
        "outputId": "67121c62-2316-446b-c7d3-61982f50fa94"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sql extension is already loaded. To reload it, use:\n",
            "  %reload_ext sql\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "sqlite:///coffee.db"
      ],
      "metadata": {
        "id": "1zoVi26Y6wYm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sql.connect(r'/content/coffee.db')"
      ],
      "metadata": {
        "id": "G1J0docO6dtB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def consult_api(date: str) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Recebe uma data de inicio e calcula os 30 dias anteriores para consultar\n",
        "  a API com os dados de cambio\n",
        "  \"\"\"\n",
        "  # variaveis padroes\n",
        "  df_raw = pd.DataFrame(columns=['data','response'])\n",
        "  key = 'ed07ae4f21f54ed4a4f03596639aac89'\n",
        "  symb = ','.join(['BRL','CLP','EUR'])\n",
        "  headers = {'Accept': 'application/json'}\n",
        "\n",
        "  # converter para datetime e calcular data -30 dias\n",
        "  end_date_obj = datetime.strptime(date, '%Y-%m-%d')\n",
        "  first_date = (end_date_obj - timedelta(days=30)).strftime('%Y-%m-%d')\n",
        "  start_date_obj = datetime.strptime(first_date, '%Y-%m-%d')\n",
        "\n",
        "  # gerar lista de datas entre data inicial e final\n",
        "  date_range = [(start_date_obj + timedelta(days=x)).strftime('%Y-%m-%d')\n",
        "                for x in range((end_date_obj - start_date_obj).days + 1)]\n",
        "  # iterar para coletar as respostas das APIs\n",
        "  for dt in tqdm(date_range):\n",
        "    url = (f\"https://openexchangerates.org/api/historical/{dt}.json?\"\n",
        "          f\"app_id={key}&base=USD&symbols={symb}&show_alternative=false\")\n",
        "    try:\n",
        "      response = requests.request(\"GET\", url, headers=headers,timeout=3)\n",
        "    except requests.exceptions.Timeout as errt:\n",
        "      print(\"Timeout Error:\",errt)\n",
        "    except requests.exceptions.RequestException as err:\n",
        "      print(\"OOps: Something Else\",err)\n",
        "\n",
        "    response_json = response.json()\n",
        "    new_row = pd.DataFrame([[dt,response_json]],\n",
        "                            columns=['data', 'response'])\n",
        "    df_raw = pd.concat([df_raw, new_row], ignore_index=True)\n",
        "  return df_raw\n",
        "current_date = datetime.now().strftime('%Y-%m-%d')\n",
        "df_raw = consult_api(current_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JokYdOm2ab2",
        "outputId": "a869cf38-6362-46ad-9e7d-e5a8ffec6b4b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:13<00:00,  2.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar dados Raw\n",
        "df_raw.astype(str).to_sql('raw_cambio', con=conn, if_exists='append')\n",
        "df_raw.to_csv('raw_cambio.csv')"
      ],
      "metadata": {
        "id": "wP0SI1Xun5TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratamento inicial\n",
        "df_curated = df_raw.copy()\n",
        "df_curated['moeda'] = df_curated['response'] \\\n",
        "                          .apply(lambda x: list(x['rates'].keys()))\n",
        "df_curated['cambio'] = df_curated['response'] \\\n",
        "                      .apply(lambda x: list(x['rates'].values()))\n",
        "\n",
        "df_curated = df_curated.explode(['moeda','cambio'])\n",
        "df_curated = df_curated[['data', 'moeda', 'cambio']]\n",
        "\n",
        "# Salvar Curated\n",
        "df_curated.astype(str).to_sql('curated_cambio', con=conn, if_exists='replace')"
      ],
      "metadata": {
        "id": "0aTAWqlKvMSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Devido a limitação da API eu coletei os dados de cambio completos através do\n",
        "# site https://br.investing.com/currencies/usd-brl-historical-data\n",
        "# a tabela abaixo seria a versão completa da curated_cambio\n",
        "\n",
        "url_git = 'https://raw.githubusercontent.com/xmarcelo195/coffee-etl/main/src/'\n",
        "\n",
        "# Criar uma tabela unificada com os valores de cambio\n",
        "usd_brl = pd.read_csv(f'{url_git}data/USD_BRL.csv')\n",
        "usd_brl['moeda'] = 'BRL'\n",
        "usd_clp = pd.read_csv(f'{url_git}data/USD_CLP.csv')\n",
        "usd_clp['moeda'] = 'CLP'\n",
        "usd_eur = pd.read_csv(f'{url_git}data/USD_EUR.csv')\n",
        "usd_eur['moeda'] = 'EUR'\n",
        "cambios = pd.concat([usd_brl,usd_clp,usd_eur])\n",
        "cambios = cambios[['Data','Último','moeda']]\n",
        "cambios.columns = ['Date','cambio','moeda']\n",
        "cambios['Date'] = pd.to_datetime(cambios['Date'], format='%d.%m.%Y') \\\n",
        "                                .dt.strftime('%Y-%m-%d')\n",
        "cambios['cambio'] = cambios['cambio'].str \\\n",
        "                    .replace('.', '', regex=True).str \\\n",
        "                    .replace(',', '.', regex=True).astype(float)\n",
        "# salvar cambios\n",
        "cambios.to_sql('cambios', con=conn, if_exists='replace')\n",
        "cambios.to_csv('cambios.csv',index=None)"
      ],
      "metadata": {
        "id": "3_bH-ID8vkkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import coffee\n",
        "coffee = pd.read_csv(f'{url_git}data/coffee.csv')\n",
        "\n",
        "# salvar raw coffee no sqlite\n",
        "coffee.to_sql('raw_coffee', con=conn, if_exists='replace')\n"
      ],
      "metadata": {
        "id": "RSbR9oZJJv4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criar uma copia para não modificar dados originais\n",
        "coffee_base = coffee.copy()"
      ],
      "metadata": {
        "id": "NQYJlQhqMEtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar tabela analytics\n",
        "coffee_cambio = coffee.merge(cambios, on='Date', how='left')\n",
        "\n",
        "# Colunas que o cambio influencia\n",
        "colunas_cambio = ['High', 'Low', 'Close', 'Open']\n",
        "\n",
        "# multiplicar colunas pelo cambio\n",
        "coffee_cambio[colunas_cambio] = coffee_cambio[colunas_cambio] \\\n",
        "                                .multiply(coffee_cambio['cambio'], axis=0)\n",
        "\n",
        "# ajuste decimais\n",
        "coffee_cambio[colunas_cambio] = coffee_cambio[colunas_cambio].round(4)\n",
        "\n",
        "# renomear coluna currency\n",
        "coffee_cambio['Currency'] = coffee_cambio['moeda']\n",
        "\n",
        "# manter apenas colunas importantes\n",
        "coffee_cambio = coffee_cambio[['Date','Open','High','Low',\n",
        "                               'Close','Volume','Currency']]"
      ],
      "metadata": {
        "id": "zlfZheEnM5rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unir tabela base (USD) com as tabelas tratadas (BRL, CLP, EUR)\n",
        "final_coffee = pd.concat([coffee_cambio,coffee_base], ignore_index=True)\n",
        "final_coffee = final_coffee.sort_values(by=['Date','Currency']).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "mLjSTc-vQfDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar tabela analitica\n",
        "final_coffee.to_csv('analytics_coffee.csv', index=None)\n",
        "final_coffee.to_sql('analytics_coffee', con=conn, if_exists='replace')"
      ],
      "metadata": {
        "id": "3ywO8sNnQna4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consultas SQL"
      ],
      "metadata": {
        "id": "XBFu2lCYZEjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Média de Volume Mês"
      ],
      "metadata": {
        "id": "JgdFvrRXZbSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT strftime('%Y-%m', Date) AS year_month,\n",
        "       round(AVG(Volume),2) AS avg_volume\n",
        "FROM raw_coffee\n",
        "GROUP BY year_month;"
      ],
      "metadata": {
        "id": "CpRyfLI94ybn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar Csv\n",
        "query = \"\"\"\n",
        "SELECT strftime('%Y-%m', Date) AS year_month,\n",
        "       round(AVG(Volume),2) AS avg_volume\n",
        "FROM raw_coffee\n",
        "GROUP BY year_month;\n",
        "\"\"\"\n",
        "result_df = pd.read_sql_query(query, conn)\n",
        "result_df.to_csv('media_volume_mes.csv', index=False)"
      ],
      "metadata": {
        "id": "kedDShPpUtO9"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Média de Volume Ano"
      ],
      "metadata": {
        "id": "9-vf_loKZihS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "SELECT strftime('%Y', Date) AS year,\n",
        "       round(AVG(Volume),2) AS avg_volume\n",
        "FROM raw_coffee\n",
        "GROUP BY year;"
      ],
      "metadata": {
        "id": "uc0rzYTLZXtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar Csv\n",
        "query = \"\"\"\n",
        "SELECT strftime('%Y', Date) AS year,\n",
        "       round(AVG(Volume),2) AS avg_volume\n",
        "FROM raw_coffee\n",
        "GROUP BY year;\n",
        "\"\"\"\n",
        "result_df = pd.read_sql_query(query, conn)\n",
        "result_df.to_csv('media_volume_ano.csv', index=False)"
      ],
      "metadata": {
        "id": "tBgJB85mZ8Bf"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Total de café negociado por ano e as cotações"
      ],
      "metadata": {
        "id": "RcbkbM7waOnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "WITH cte_coffee as (\n",
        "  SELECT MAX(Date) AS max_date,\n",
        "  SUM(Volume) as volume,\n",
        "  strftime('%Y', Date) as year\n",
        "  FROM raw_coffee\n",
        "  GROUP BY year)\n",
        "select\n",
        "  a.year,\n",
        "  a.volume,\n",
        "  1 as last_usd,\n",
        "  MAX(CASE WHEN c.moeda = 'EUR' THEN c.cambio END) AS last_eur,\n",
        "  MAX(CASE WHEN c.moeda = 'BRL' THEN c.cambio END) AS last_brl,\n",
        "  MAX(CASE WHEN c.moeda = 'CLP' THEN c.cambio END) AS last_clp\n",
        "from cte_coffee a\n",
        "left join cambios c on c.Date = a.max_date\n",
        "group by year"
      ],
      "metadata": {
        "id": "NTpwRDoPaN5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar Csv\n",
        "query = \"\"\"\n",
        "WITH cte_coffee as (\n",
        "  SELECT MAX(Date) AS max_date,\n",
        "  SUM(Volume) as volume,\n",
        "  strftime('%Y', Date) as year\n",
        "  FROM raw_coffee\n",
        "  GROUP BY year)\n",
        "select\n",
        "  a.year,\n",
        "  a.volume,\n",
        "  1 as last_usd,\n",
        "  MAX(CASE WHEN c.moeda = 'EUR' THEN c.cambio END) AS last_eur,\n",
        "  MAX(CASE WHEN c.moeda = 'BRL' THEN c.cambio END) AS last_brl,\n",
        "  MAX(CASE WHEN c.moeda = 'CLP' THEN c.cambio END) AS last_clp\n",
        "from cte_coffee a\n",
        "left join cambios c on c.Date = a.max_date\n",
        "group by year\n",
        "\"\"\"\n",
        "result_df = pd.read_sql_query(query, conn)\n",
        "result_df.to_csv('total_negociado_ano.csv', index=False)"
      ],
      "metadata": {
        "id": "vppnEejdPgXv"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Maior volume no período e as cotações do dia"
      ],
      "metadata": {
        "id": "ybd-v8zSJu9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "WITH cte_coffee as (\n",
        "  SELECT\n",
        "  Date\n",
        "  FROM raw_coffee\n",
        "where\n",
        "  volume = (SELECT MAX(volume) FROM analytics_coffee)\n",
        ")\n",
        "select\n",
        "a.Date,\n",
        "a.Volume,\n",
        "1 as last_usd,\n",
        "MAX(CASE WHEN c.moeda = 'EUR' THEN c.cambio END) AS last_eur,\n",
        "MAX(CASE WHEN c.moeda = 'BRL' THEN c.cambio END) AS last_brl,\n",
        "MAX(CASE WHEN c.moeda = 'CLP' THEN c.cambio END) AS last_clp\n",
        "from raw_coffee a\n",
        "left join cambios c on c.Date = a.Date\n",
        "where\n",
        "a.Date in (SELECT Date from cte_coffee)\n",
        "group by a.Date"
      ],
      "metadata": {
        "id": "gdKvHTkp4Zfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar Csv\n",
        "query = \"\"\"\n",
        "WITH cte_coffee as (\n",
        "  SELECT\n",
        "  Date\n",
        "  FROM raw_coffee\n",
        "where\n",
        "  volume = (SELECT MAX(volume) FROM analytics_coffee)\n",
        ")\n",
        "select\n",
        "a.Date,\n",
        "a.Volume,\n",
        "1 as last_usd,\n",
        "MAX(CASE WHEN c.moeda = 'EUR' THEN c.cambio END) AS last_eur,\n",
        "MAX(CASE WHEN c.moeda = 'BRL' THEN c.cambio END) AS last_brl,\n",
        "MAX(CASE WHEN c.moeda = 'CLP' THEN c.cambio END) AS last_clp\n",
        "from raw_coffee a\n",
        "left join cambios c on c.Date = a.Date\n",
        "where\n",
        "a.Date in (SELECT Date from cte_coffee)\n",
        "group by a.Date\n",
        "\"\"\"\n",
        "result_df = pd.read_sql_query(query, conn)\n",
        "result_df.to_csv('data_maior_volume.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "kojJ7ODSJrl9"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testes"
      ],
      "metadata": {
        "id": "EmRK88tUAfyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar expectativas\n",
        "context = ge.get_context()\n",
        "validator = context.sources.pandas_default.read_csv(\n",
        "    \"/content/analytics_coffee.csv\"\n",
        ")\n",
        "validator.expect_column_to_exist('Volume')\n",
        "validator.expect_column_to_exist('Close')\n",
        "validator.expect_column_to_exist('Currency')\n",
        "validator.expect_column_values_to_not_be_null(\"Volume\")\n",
        "validator.expect_column_values_to_be_of_type('Volume','int')\n",
        "validator.save_expectation_suite()\n",
        "\n",
        "checkpoint = context.add_or_update_checkpoint(\n",
        "    name=\"my_quickstart_checkpoint\",\n",
        "    validator=validator,\n",
        ")\n",
        "checkpoint_result = checkpoint.run()\n",
        "context.view_validation_result(checkpoint_result)"
      ],
      "metadata": {
        "id": "tOfN26NvAhSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRESULTS:\\n\")\n",
        "print(f'Success: {checkpoint_result.success}')\n",
        "#checkpoint_result['run_results']"
      ],
      "metadata": {
        "id": "dOB9eWQoM1QW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}